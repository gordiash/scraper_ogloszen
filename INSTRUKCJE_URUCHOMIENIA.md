# INSTRUKCJE URUCHOMIENIA SCRAPERA NIERUCHOMOÅšCI

## âœ… GOTOWY DO UÅ»YCIA!

Scraper zostaÅ‚ pomyÅ›lnie zainstalowany i przetestowany z peÅ‚nÄ… obsÅ‚ugÄ… Selenium. Oto jak go uÅ¼ywaÄ‡:

## ğŸš€ Szybki Start

### 1. Podstawowe pakiety sÄ… juÅ¼ zainstalowane
```bash
# Te pakiety zostaÅ‚y juÅ¼ zainstalowane:
# requests, beautifulsoup4, supabase, fake-useragent, python-dotenv, selenium
```

### 2. Przetestuj scrapery z Selenium
```bash
python test_selenium_scrapers.py
```

### 3. Przetestuj wszystkie scrapery (bez bazy danych)
```bash
python test_scraper_no_db.py
```

## ğŸ“Š WYNIKI TESTÃ“W - AKTUALNE STANIE

### âœ… **DZIAÅAJÄ„CE SCRAPERY Z SELENIUM:**
- **Freedom.pl** - **20 ogÅ‚oszeÅ„** z cenami i linkami
- **Gratka.pl** - **37 ogÅ‚oszeÅ„** z linkami
- **Metrohouse.pl** - **63 ogÅ‚oszenia** z linkami
- **Domiporta.pl** - **36 ogÅ‚oszeÅ„** z cenami i linkami

### âœ… **DZIAÅAJÄ„CE SCRAPERY Z REQUESTS:**
- **OLX.pl** - **10+ ogÅ‚oszeÅ„** z cenami i lokalizacjami
- **Otodom.pl** - **40+ ogÅ‚oszeÅ„** (tytuÅ‚y i linki)

## ğŸ“ˆ **PODSUMOWANIE WYDAJNOÅšCI:**
- **Wszystkie 6 portali dziaÅ‚ajÄ…**: 6/6 âœ…
- **Selenium scrapery**: 4/4 âœ… (156 ogÅ‚oszeÅ„)
- **Requests scrapery**: 2/2 âœ… (50+ ogÅ‚oszeÅ„)
- **ÅÄ…cznie**: **200+ ogÅ‚oszeÅ„** z rÃ³Å¼nych portali

## ğŸ”§ KONFIGURACJA SELENIUM

Selenium jest juÅ¼ skonfigurowane i gotowe do uÅ¼ycia:
- **Headless mode**: DomyÅ›lnie wÅ‚Ä…czony
- **Timeout**: 20 sekund
- **User-Agent**: Losowy (anti-detection)
- **Anti-bot protection**: Podstawowe zabezpieczenia

### Konfiguracja w `config.py`:
```python
SELENIUM_ENABLED = True
SELENIUM_HEADLESS = True
SELENIUM_TIMEOUT = 20
SELENIUM_WAIT_TIME = 2
```

## ğŸ—ƒï¸ KONFIGURACJA SUPABASE (OPCJONALNA)

JeÅ›li chcesz zapisywaÄ‡ dane do bazy Supabase:

### 1. StwÃ³rz konto na supabase.com

### 2. UtwÃ³rz tabelÄ™ (POPRAWIONA WERSJA):
```sql
CREATE TABLE ogloszenia (
    id SERIAL PRIMARY KEY,
    title TEXT,
    price NUMERIC,
    price_currency TEXT,
    price_original TEXT,
    location TEXT,
    url TEXT UNIQUE,
    area TEXT,
    rooms TEXT,
    description TEXT,
    source TEXT,
    scraped_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### 3. Ustaw zmienne Å›rodowiskowe:
```bash
# Windows PowerShell:
$env:SUPABASE_URL="https://twoj-projekt.supabase.co"
$env:SUPABASE_KEY="twÃ³j_anon_key"

# Linux/Mac:
export SUPABASE_URL="https://twoj-projekt.supabase.co"
export SUPABASE_KEY="twÃ³j_anon_key"
```

### 4. Przetestuj poÅ‚Ä…czenie z Supabase:
```bash
python test_supabase.py
```

### 5. Uruchom z zapisem do bazy:
```bash
python main.py
```

## ğŸ“ DOSTÄ˜PNE PLIKI

### GÅ‚Ã³wne pliki:
- `test_selenium_scrapers.py` - **TEST WSZYSTKICH SCRAPERÃ“W Z SELENIUM** (POLECANE)
- `working_demo.py` - **DZIAÅAJÄ„CA DEMONSTRACJA** bez Selenium
- `test_scraper_no_db.py` - Test wszystkich scraperÃ³w bez bazy
- `test_supabase.py` - **TEST ZAPISU DO SUPABASE**
- `main.py` - PeÅ‚ny scraper z zapisem do Supabase

### Scrapery z Selenium (katalog `scrapers/`):
- `freedom.py` - **DZIAÅA** (20 ogÅ‚oszeÅ„) âš¡ Selenium
- `gratka.py` - **DZIAÅA** (37 ogÅ‚oszeÅ„) âš¡ Selenium
- `metrohouse.py` - **DZIAÅA** (63 ogÅ‚oszenia) âš¡ Selenium
- `domiporta.py` - **DZIAÅA** (36 ogÅ‚oszeÅ„) âš¡ Selenium

### Scrapery z Requests:
- `otodom.py` - **DZIAÅA** (40+ ogÅ‚oszeÅ„)
- `olx.py` - **DZIAÅA** (10+ ogÅ‚oszeÅ„)

### Pomocnicze:
- `utils.py` - Funkcje pomocnicze + **obsÅ‚uga Selenium**
- `supabase_utils.py` - ObsÅ‚uga bazy danych (POPRAWIONA)
- `config.py` - Konfiguracja + **ustawienia Selenium**
- `debug_selenium.py` - **NARZÄ˜DZIE DEBUG dla portali z Selenium**

## ğŸ¯ PRZYKÅADOWE WYNIKI

Po uruchomieniu `test_selenium_scrapers.py` otrzymasz:

```
============================================================
PODSUMOWANIE TESTÃ“W SELENIUM
============================================================
Freedom.pl     :  20 ogÅ‚oszeÅ„ âœ“ DZIAÅA
Gratka.pl      :  37 ogÅ‚oszeÅ„ âœ“ DZIAÅA
Metrohouse.pl  :  63 ogÅ‚oszeÅ„ âœ“ DZIAÅA
Domiporta.pl   :  36 ogÅ‚oszeÅ„ âœ“ DZIAÅA

DziaÅ‚ajÄ…ce scrapery: 4/4
ÅÄ…cznie ogÅ‚oszeÅ„: 156

ğŸ‰ SUKCES! Wszystkie scrapery z Selenium dziaÅ‚ajÄ…!
```

## ğŸš¨ ROZWIÄ„ZYWANIE PROBLEMÃ“W

### BÅ‚Ä…d: ModuleNotFoundError
```bash
pip install requests beautifulsoup4 supabase fake-useragent python-dotenv selenium
```

### BÅ‚Ä…d: ChromeDriver
JeÅ›li brak ChromeDriver:
1. **Windows**: ChromeDriver powinien byÄ‡ automatycznie dostÄ™pny
2. **Linux/Mac**: `sudo apt install chromium-chromedriver` lub pobierz z https://chromedriver.chromium.org/

### Selenium dziaÅ‚a wolno
- To normalne - Selenium Å‚aduje peÅ‚nÄ… stronÄ™ z JavaScript
- Typowy czas: 3-5 sekund na stronÄ™
- MoÅ¼na zmniejszyÄ‡ `SELENIUM_WAIT_TIME` w config.py

### Blokowanie przez portal
- ZwiÄ™ksz opÃ³Åºnienia miÄ™dzy requestami
- ZmieÅ„ User-Agent headers (automatyczne)
- Selenium ma lepszÄ… ochronÄ™ przed wykryciem

### BÅ‚Ä…d: "Could not find column in schema cache"
To znaczy Å¼e tabela w Supabase nie ma wszystkich kolumn. **RozwiÄ…zanie automatyczne** - kod filtruje kolumny.

## âš¡ GOTOWE KOMENDY

```bash
# Test Selenium (NAJLEPSZY):
python test_selenium_scrapers.py

# Test bez Selenium:
python working_demo.py

# Test wszystkich scraperÃ³w:
python test_scraper_no_db.py

# Test Supabase:
python test_supabase.py

# PeÅ‚ny scraper z Supabase (po konfiguracji):
python main.py

# Debug konkretnego portalu:
python debug_selenium.py
```

## ğŸ‰ SUKCES!

Scraper nieruchomoÅ›ci jest w peÅ‚ni gotowy:
- âœ… **6 dziaÅ‚ajÄ…cych scraperÃ³w** (4 z Selenium + 2 z Requests)
- âœ… Pobiera **200+ ogÅ‚oszeÅ„** z najwiÄ™kszych polskich portali
- âœ… Ekstraktuje ceny, tytuÅ‚y, linki, lokalizacje
- âœ… **Selenium** dla nowoczesnych portali z JavaScript
- âœ… Zapisuje do Supabase (po konfiguracji)
- âœ… **Anti-detection** zabezpieczenia
- âœ… Automatyczne filtrowanie kolumn bazy danych
- âœ… Gotowy do rozbudowy o kolejne portale 