# INSTRUKCJE URUCHOMIENIA SCRAPERA NIERUCHOMOÅšCI

## âœ… GOTOWY DO UÅ»YCIA!

Scraper zostaÅ‚ pomyÅ›lnie zainstalowany i przetestowany. Oto jak go uÅ¼ywaÄ‡:

## ğŸš€ Szybki Start

### 1. Podstawowe pakiety sÄ… juÅ¼ zainstalowane
```bash
# Te pakiety zostaÅ‚y juÅ¼ zainstalowane:
# requests, beautifulsoup4, supabase, fake-useragent, python-dotenv
```

### 2. Przetestuj scraper (bez bazy danych)
```bash
python working_demo.py
```

### 3. Uruchom testy wszystkich scraperÃ³w
```bash
python test_scraper_no_db.py
```

## ğŸ“Š WYNIKI TESTÃ“W

**âœ… DZIAÅAJÄ„CE SCRAPERY:**
- **OLX.pl** - pobiera 10+ ogÅ‚oszeÅ„ z cenami i lokalizacjami
- **Otodom.pl** - pobiera 40+ ogÅ‚oszeÅ„ (tytuÅ‚y i linki)

**âš ï¸ DO POPRAWIENIA:**
- **Freedom.pl** - wymaga aktualizacji selektorÃ³w CSS
- **Gratka.pl** - wymaga aktualizacji selektorÃ³w CSS  
- **Metrohouse.pl** - wymaga aktualizacji selektorÃ³w CSS
- **Domiporta.pl** - wymaga aktualizacji selektorÃ³w CSS

## ğŸ—ƒï¸ KONFIGURACJA SUPABASE (OPCJONALNA)

JeÅ›li chcesz zapisywaÄ‡ dane do bazy Supabase:

### 1. StwÃ³rz konto na supabase.com

### 2. UtwÃ³rz tabelÄ™ (POPRAWIONA WERSJA):
```sql
CREATE TABLE ogloszenia (
    id SERIAL PRIMARY KEY,
    title TEXT,
    price NUMERIC,
    price_currency TEXT,
    price_original TEXT,
    location TEXT,
    url TEXT UNIQUE,
    area TEXT,
    rooms TEXT,
    description TEXT,
    source TEXT,
    scraped_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### 3. Ustaw zmienne Å›rodowiskowe:
```bash
# Windows PowerShell:
$env:SUPABASE_URL="https://twoj-projekt.supabase.co"
$env:SUPABASE_KEY="twÃ³j_anon_key"

# Linux/Mac:
export SUPABASE_URL="https://twoj-projekt.supabase.co"
export SUPABASE_KEY="twÃ³j_anon_key"
```

### 4. Przetestuj poÅ‚Ä…czenie z Supabase:
```bash
python test_supabase.py
```

### 5. Uruchom z zapisem do bazy:
```bash
python main.py
```

## ğŸ“ DOSTÄ˜PNE PLIKI

### GÅ‚Ã³wne pliki:
- `working_demo.py` - **DZIAÅAJÄ„CA DEMONSTRACJA** (POLECANE)
- `test_scraper_no_db.py` - Test wszystkich scraperÃ³w bez bazy
- `test_supabase.py` - **TEST ZAPISU DO SUPABASE**
- `simple_test.py` - Test podstawowych funkcji
- `main.py` - PeÅ‚ny scraper z zapisem do Supabase

### Scrapery (katalog `scrapers/`):
- `otodom.py` - **DZIAÅA** (40+ ogÅ‚oszeÅ„)
- `olx.py` - **DZIAÅA** (10+ ogÅ‚oszeÅ„)
- `freedom.py` - do poprawienia
- `gratka.py` - do poprawienia  
- `metrohouse.py` - do poprawienia
- `domiporta.py` - do poprawienia

### Pomocnicze:
- `utils.py` - Funkcje pomocnicze
- `supabase_utils.py` - ObsÅ‚uga bazy danych (POPRAWIONA)
- `config.py` - Konfiguracja

## ğŸ”§ DOSTOSOWYWANIE SCRAPERÃ“W

Aby poprawiÄ‡ scrapery ktÃ³re nie dziaÅ‚ajÄ…:

1. **OtwÃ³rz plik scrapera** (np. `scrapers/freedom.py`)
2. **SprawdÅº strukturÄ™ HTML** strony w przeglÄ…darce (F12)
3. **Zaktualizuj selektory CSS** w funkcji `parse_*_listing()`
4. **Przetestuj zmiany** uÅ¼ywajÄ…c `debug_scraper.py`

### PrzykÅ‚ad aktualizacji selektorÃ³w:
```python
# Stare selektory:
offers = soup.select(".property-item")

# Nowe selektory (sprawdÅº w przeglÄ…darce):
offers = soup.select(".listing-card") or soup.select("[data-testid='listing']")
```

## ğŸ¯ PRZYKÅADOWE WYNIKI

Po uruchomieniu `working_demo.py` otrzymasz:

```
============================================================
DEMONSTRACJA SCRAPERA NIERUCHOMOÅšCI
============================================================

=== PODSUMOWANIE ===
ÅÄ…cznie pobrano: 12 ogÅ‚oszeÅ„
OLX: 10 ogÅ‚oszeÅ„
PrzykÅ‚adowe: 2 ogÅ‚oszeÅ„

=== PRZYKÅADOWE OGÅOSZENIA ===
--- OgÅ‚oszenie 1 ---
TytuÅ‚: âœ… Ostatnie maÅ‚e mieszkanie 38mÂ² z ogrÃ³dkiem âœ…
Cena: 305579.7 zÅ‚
URL: https://www.otodom.pl/pl/oferta/...
Å¹rÃ³dÅ‚o: olx.pl
```

## ğŸš¨ ROZWIÄ„ZYWANIE PROBLEMÃ“W

### BÅ‚Ä…d: ModuleNotFoundError
```bash
pip install requests beautifulsoup4 supabase fake-useragent python-dotenv
```

### BÅ‚Ä…d: "Could not find column in schema cache"
To znaczy Å¼e tabela w Supabase nie ma wszystkich kolumn. RozwiÄ…zania:

**1. Dodaj brakujÄ…ce kolumny:**
```sql
ALTER TABLE ogloszenia 
ADD COLUMN IF NOT EXISTS scraper_version TEXT,
ADD COLUMN IF NOT EXISTS source_page INTEGER;
```

**2. Lub uÅ¼yj kodu ktÃ³ry automatycznie filtruje kolumny** (juÅ¼ naprawione w `supabase_utils.py`)

### Selektory nie dziaÅ‚ajÄ…
- Struktura HTML portali czÄ™sto siÄ™ zmienia
- SprawdÅº aktualnÄ… strukturÄ™ w przeglÄ…darce (F12)
- Zaktualizuj selektory CSS w odpowiednim pliku

### Blokowanie przez portal
- ZwiÄ™ksz opÃ³Åºnienia miÄ™dzy requestami
- ZmieÅ„ User-Agent headers
- UÅ¼yj proxy (opcjonalnie)

## âš¡ GOTOWE KOMENDY

```bash
# Test podstawowy (POLECANE):
python working_demo.py

# Test wszystkich scraperÃ³w:
python test_scraper_no_db.py

# Test Supabase:
python test_supabase.py

# PeÅ‚ny scraper z Supabase (po konfiguracji):
python main.py

# Debug konkretnego scrapera:
python debug_scraper.py
```

## ğŸ‰ SUKCES!

Scraper nieruchomoÅ›ci jest gotowy do uÅ¼ycia! 
- âœ… Pobiera dane z OLX i Otodom
- âœ… Ekstraktuje ceny, tytuÅ‚y, linki
- âœ… Zapisuje do Supabase (po konfiguracji)
- âœ… Gotowy do rozbudowy o kolejne portale
- âœ… Automatyczne filtrowanie kolumn bazy danych 