# ğŸ  SCRAPER NIERUCHOMOÅšCI - DOKUMENTACJA

## ğŸ“‹ Opis projektu

Automatyczny scraper nieruchomoÅ›ci z portalu Otodom.pl z kompletnym pipeline:
- ğŸ” **Scrapowanie** ogÅ‚oszeÅ„ z Otodom.pl
- ğŸ“ **Parsing adresÃ³w** na komponenty (miasto, dzielnica, ulica)
- ğŸŒ **Geocoding** - uzupeÅ‚nianie wspÃ³Å‚rzÄ™dnych geograficznych
- ğŸ’¾ **Zapis do bazy** Supabase z walidacjÄ…

## ğŸš€ Szybki start

### 1. Instalacja zaleÅ¼noÅ›ci
```bash
pip install -r requirements.txt
```

### 2. Konfiguracja Supabase
```bash
# Skopiuj plik przykÅ‚adowy
cp env_example.txt .env

# Edytuj .env i uzupeÅ‚nij:
SUPABASE_URL=https://twoj-projekt.supabase.co
SUPABASE_KEY=twoj_anon_key
```

### 3. Uruchomienie kompletnego pipeline
```bash
# Automatyczny pipeline (scraping + parsing + geocoding)
python scripts/scraper_main.py --pages 5 --geocoding-limit 100

# Tylko scraping
python src/scrapers/otodom_scraper.py

# Tylko parsing adresÃ³w
python src/parsers/address_parser.py --process

# Tylko geocoding
python src/geocoding/geocoder.py --update
```

## ğŸ“ Struktura projektu

```
scraper/
â”œâ”€â”€ scripts/                    # GÅ‚Ã³wne skrypty
â”‚   â””â”€â”€ scraper_main.py        # Kompletny pipeline
â”œâ”€â”€ src/                       # Kod ÅºrÃ³dÅ‚owy
â”‚   â”œâ”€â”€ scrapers/              # Scrapery portali
â”‚   â”‚   â””â”€â”€ otodom_scraper.py  # Scraper Otodom.pl
â”‚   â”œâ”€â”€ parsers/               # Parsery danych
â”‚   â”‚   â””â”€â”€ address_parser.py  # Parser adresÃ³w
â”‚   â””â”€â”€ geocoding/             # Geocoding
â”‚       â””â”€â”€ geocoder.py        # Geocoder wspÃ³Å‚rzÄ™dnych
â”œâ”€â”€ .github/workflows/         # GitHub Actions
â”‚   â””â”€â”€ scraper.yml           # Automatyczne scrapowanie
â”œâ”€â”€ docs/                      # Dokumentacja
â”œâ”€â”€ sql/                       # Skrypty SQL
â””â”€â”€ tests/                     # Testy
```

## ğŸ”§ Konfiguracja

### Zmienne Å›rodowiskowe (.env)
```bash
SUPABASE_URL=https://twoj-projekt.supabase.co
SUPABASE_KEY=twoj_anon_key
```

### Struktura bazy danych

#### Tabela `listings`
```sql
CREATE TABLE listings (
    id SERIAL PRIMARY KEY,
    title TEXT,
    price INTEGER,
    price_currency TEXT DEFAULT 'zÅ‚',
    price_original TEXT,
    location TEXT,
    url TEXT UNIQUE,
    area TEXT,
    rooms TEXT,
    description TEXT,
    source TEXT DEFAULT 'otodom.pl',
    scraped_at TIMESTAMP DEFAULT NOW()
);
```

#### Tabela `addresses`
```sql
CREATE TABLE addresses (
    id SERIAL PRIMARY KEY,
    full_address TEXT NOT NULL,
    street_name TEXT,
    district TEXT,
    sub_district TEXT,
    city TEXT,
    province TEXT,
    latitude DECIMAL(10, 8),
    longitude DECIMAL(11, 8),
    foreign_key INTEGER REFERENCES listings(id)
);
```

## ğŸ¤– GitHub Actions

Projekt zawiera automatyczne scrapowanie przez GitHub Actions:

### Harmonogram
- **Codziennie o 6:00 UTC** (8:00 czasu polskiego)
- **RÄ™czne uruchomienie** przez GitHub UI

### Konfiguracja secrets
W ustawieniach repozytorium dodaj:
- `SUPABASE_URL` - URL projektu Supabase
- `SUPABASE_KEY` - Klucz anon/public

### Uruchomienie rÄ™czne
1. PrzejdÅº do zakÅ‚adki **Actions**
2. Wybierz **Scraper nieruchomoÅ›ci**
3. Kliknij **Run workflow**

## ğŸ“Š FunkcjonalnoÅ›ci

### ğŸ” Scrapowanie
- **Portal**: Otodom.pl
- **Dane**: TytuÅ‚, cena, lokalizacja, powierzchnia, pokoje, URL
- **Technologia**: Selenium (obsÅ‚uga JavaScript)
- **Anti-detection**: Losowe opÃ³Åºnienia, User-Agent

### ğŸ“ Parsing adresÃ³w
- **Rozdzielanie** lokalizacji na komponenty
- **Normalizacja** nazw miast i ulic
- **ObsÅ‚uga** rÃ³Å¼nych formatÃ³w adresÃ³w
- **Walidacja** poprawnoÅ›ci danych

### ğŸŒ Geocoding
- **API**: OpenStreetMap Nominatim
- **SkutecznoÅ›Ä‡**: ~92% (ulepszone zapytania)
- **Fallback**: Zapytania uproszczone
- **Walidacja**: Sprawdzanie granic Polski
- **Rate limiting**: Zgodnie z wymaganiami API

### ğŸ’¾ Baza danych
- **Platforma**: Supabase (PostgreSQL)
- **Deduplikacja**: Automatyczne wykrywanie duplikatÃ³w
- **Walidacja**: Sprawdzanie kompletnoÅ›ci danych
- **Indeksy**: Optymalizacja wydajnoÅ›ci

## ğŸ“ˆ Statystyki

### WydajnoÅ›Ä‡ scrapowania
- **~40-50 ogÅ‚oszeÅ„** na stronÄ™ Otodom.pl
- **~200-250 ogÅ‚oszeÅ„** z 5 stron
- **Czas**: ~2-3 minuty na stronÄ™ (Selenium)

### SkutecznoÅ›Ä‡ geocodingu
- **92%** skutecznoÅ›Ä‡ z uproszczonymi zapytaniami
- **100%** dla gÅ‚Ã³wnych miast Polski
- **Fallback**: Dodatkowe ~5-10% skutecznoÅ›ci

### JakoÅ›Ä‡ danych
- **95%+** ogÅ‚oszeÅ„ z tytuÅ‚em i URL
- **80%+** ogÅ‚oszeÅ„ z cenÄ…
- **70%+** ogÅ‚oszeÅ„ z lokalizacjÄ…
- **60%+** ogÅ‚oszeÅ„ z powierzchniÄ…/pokojami

## ğŸ› ï¸ RozwÃ³j

### Dodawanie nowych portali
1. StwÃ³rz nowy scraper w `src/scrapers/`
2. Zaimplementuj funkcjÄ™ `get_[portal]_listings()`
3. Dodaj do `scripts/scraper_main.py`

### Ulepszanie geocodingu
1. Edytuj `src/geocoding/geocoder.py`
2. Dodaj nowe poprawki miast w `city_fixes`
3. Dostosuj progi podobieÅ„stwa

### Testy
```bash
# Test scrapera
python src/scrapers/otodom_scraper.py

# Test parsera
python src/parsers/address_parser.py --test

# Test geocodera
python src/geocoding/geocoder.py --test
```

## ğŸ” RozwiÄ…zywanie problemÃ³w

### BÅ‚Ä™dy scrapowania
- **Selenium timeout**: ZwiÄ™ksz `SELENIUM_TIMEOUT` w utils.py
- **Brak ogÅ‚oszeÅ„**: SprawdÅº selektory CSS (mogÅ‚y siÄ™ zmieniÄ‡)
- **Blokowanie**: ZwiÄ™ksz opÃ³Åºnienia miÄ™dzy requestami

### BÅ‚Ä™dy geocodingu
- **Niska skutecznoÅ›Ä‡**: SprawdÅº jakoÅ›Ä‡ danych adresowych
- **Rate limiting**: ZwiÄ™ksz `DELAY_BETWEEN_REQUESTS`
- **BÅ‚Ä™dne wspÃ³Å‚rzÄ™dne**: SprawdÅº walidacjÄ™ granic Polski

### BÅ‚Ä™dy bazy danych
- **Connection error**: SprawdÅº zmienne Å›rodowiskowe
- **Missing columns**: Uruchom skrypty SQL z katalogu `sql/`
- **Duplicate key**: Normalne - duplikaty sÄ… pomijane

## ğŸ“ Wsparcie

### Logi
- **Plik**: `scraper.log`
- **Poziom**: INFO (moÅ¼na zmieniÄ‡ na DEBUG)
- **Rotacja**: Automatyczna

### Monitoring
- **GitHub Actions**: Logi w zakÅ‚adce Actions
- **Supabase**: Dashboard z metrykami
- **Lokalne**: SzczegÃ³Å‚owe logi w konsoli

### Kontakt
- **Issues**: GitHub Issues dla bÅ‚Ä™dÃ³w
- **Dokumentacja**: Ten plik README
- **Konfiguracja**: Pliki w katalogu `docs/`

---

## ğŸ¯ Roadmapa

### KrÃ³tkoterminowe
- [ ] Dodanie OLX.pl scraper
- [ ] Dashboard z wykresami
- [ ] Alerty email o nowych ofertach

### DÅ‚ugoterminowe  
- [ ] Analiza trendÃ³w cenowych
- [ ] API REST do eksportu danych
- [ ] Mapa z lokalizacjami
- [ ] Funkcje AI do kategoryzacji

---

**Ostatnia aktualizacja**: GrudzieÅ„ 2024  
**Wersja**: 2.0  
**Status**: Produkcyjny âœ… 