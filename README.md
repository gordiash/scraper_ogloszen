# ğŸ  SCRAPER NIERUCHOMOÅšCI - POLSKA

Zaawansowany system scrapowania ogÅ‚oszeÅ„ nieruchomoÅ›ci z najwiÄ™kszych polskich portali + **inteligentne wykrywanie duplikatÃ³w**.

## âœ¨ **FUNKCJONALNOÅšCI**

âœ… **6 dziaÅ‚ajÄ…cych scraperÃ³w** (4 z Selenium + 2 z Requests)  
âœ… **200+ ogÅ‚oszeÅ„** z rÃ³Å¼nych portali  
âœ… **ğŸ” DEDUPLIKACJA** - usuwa ~35% duplikatÃ³w miÄ™dzy portalami  
âœ… **Inteligentne porÃ³wnywanie** tytuÅ‚Ã³w, cen, powierzchni, lokalizacji  
âœ… **Priorytet najlepszych ÅºrÃ³deÅ‚** (Otodom > OLX > inne)  
âœ… **Selenium** dla nowoczesnych portali JavaScript  
âœ… **Anti-detection** zabezpieczenia  
âœ… **Supabase** integration  
âœ… **Automatyczne filtrowanie** danych  
âœ… **ğŸŒ GEOCODING** - automatyczne wspÃ³Å‚rzÄ™dne geograficzne  
âœ… **Parser adresÃ³w** - rozdzielanie lokalizacji na komponenty

## ğŸ¯ **OBSÅUGIWANE PORTALE**

### ğŸš€ **Scrapery z Selenium** (JavaScript)
- **Freedom.pl** - 20 ogÅ‚oszeÅ„ z cenami
- **Gratka.pl** - 37 ogÅ‚oszeÅ„ 
- **Metrohouse.pl** - 63 ogÅ‚oszenia
- **Domiporta.pl** - 36 ogÅ‚oszeÅ„ z cenami

### ğŸŒ **Scrapery z Requests** (klasyczne)
- **OLX.pl** - 10+ ogÅ‚oszeÅ„ z cenami i lokalizacjami
- **Otodom.pl** - 40+ ogÅ‚oszeÅ„

## ğŸ” **DEDUPLIKACJA - NOWA FUNKCJONALNOÅšÄ†**

### âœ¨ **Jak dziaÅ‚a:**
```
ğŸ“Š Przed: 196 ogÅ‚oszeÅ„ z 6 portali
ğŸ§¹ Po:   128 unikatowych ogÅ‚oszeÅ„  
ğŸ”„ Duplikaty: 68 (35% skutecznoÅ›ci)
```

### ğŸ› ï¸ **Algorytm podobieÅ„stwa:**
- **40%** - Fuzzy matching tytuÅ‚Ã³w
- **25%** - PorÃ³wnanie cen (Â±5% tolerancja)
- **15%** - Powierzchnia (Â±10% tolerancja)
- **10%** - Liczba pokoi (dokÅ‚adne)
- **10%** - Lokalizacja (czÄ™Å›ciowe)

### ğŸ“Š **Ranking ÅºrÃ³deÅ‚** (priorytety):
1. **otodom.pl** ğŸ¥‡
2. **olx.pl** ğŸ¥ˆ  
3. **domiporta.pl** ğŸ¥‰
4. **gratka.pl**
5. **metrohouse.pl**
6. **freedom.pl**

## ğŸ“Š **WYNIKI TESTÃ“W Z DEDUPLIKACJÄ„**

```bash
================================================================================
ğŸ  PEÅNA DEMONSTRACJA SCRAPERA NIERUCHOMOÅšCI
================================================================================
ğŸ“Š Testuje wszystkie 6 dziaÅ‚ajÄ…cych portali:
   ğŸ”¸ 4 scrapery z Selenium (nowoczesne portale)
   ğŸ”¸ 2 scrapery z Requests (klasyczne portale)  
   ğŸ”¸ âœ¨ WYKRYWANIE DUPLIKATÃ“W miÄ™dzy portalami

ğŸ” WYKRYWANIE DUPLIKATÃ“W
ğŸ“Š ÅÄ…cznie pobrano: 196 ogÅ‚oszeÅ„
ğŸ§¹ Po deduplikacji: 128 unikatowych ogÅ‚oszeÅ„
ğŸ”„ UsuniÄ™to duplikatÃ³w: 68

ğŸ“Š Duplikaty per portal:
   â€¢ domiporta.pl: 11 duplikatÃ³w
   â€¢ freedom.pl: 19 duplikatÃ³w  
   â€¢ metrohouse.pl: 35 duplikatÃ³w
   â€¢ otodom.pl: 3 duplikatÃ³w

ğŸ‰ SUKCES! System scrapowania z deduplikacjÄ… dziaÅ‚a!
```

## ğŸš€ **SZYBKI START**

### 1. Instalacja
```bash
git clone [repository]
cd scraper
pip install -r requirements.txt
```

### 2. Test z deduplikacjÄ… (POLECANE)
```bash
# PeÅ‚na demonstracja z deduplikacjÄ…
python complete_demo.py

# Test samej deduplikacji
python test_deduplicate.py

# Test Selenium bez deduplikacji
python test_selenium_scrapers.py
```

### 3. Konfiguracja Supabase (opcjonalna)
```bash
# Ustaw zmienne Å›rodowiskowe
$env:SUPABASE_URL="https://twoj-projekt.supabase.co"
$env:SUPABASE_KEY="twÃ³j_anon_key"

# Test poÅ‚Ä…czenia
python test_supabase.py

# PeÅ‚ny scraper z bazÄ… + deduplikacjÄ…
python main.py
```

## ğŸ”§ **ARCHITEKTURA**

```
scraper/
â”œâ”€â”€ scrapers/           # ModuÅ‚y scraperÃ³w
â”‚   â”œâ”€â”€ freedom.py     # âš¡ Selenium 
â”‚   â”œâ”€â”€ gratka.py      # âš¡ Selenium
â”‚   â”œâ”€â”€ metrohouse.py  # âš¡ Selenium
â”‚   â”œâ”€â”€ domiporta.py   # âš¡ Selenium
â”‚   â”œâ”€â”€ olx.py         # ğŸŒ Requests
â”‚   â””â”€â”€ otodom.py      # ğŸŒ Requests
â”œâ”€â”€ utils.py           # ObsÅ‚uga Selenium + Requests + ğŸ” DEDUPLIKACJA
â”œâ”€â”€ config.py          # Konfiguracja + Selenium
â”œâ”€â”€ supabase_utils.py  # Integracja z bazÄ…
â”œâ”€â”€ main.py            # GÅ‚Ã³wny scraper + deduplikacja
â”œâ”€â”€ complete_demo.py   # ğŸŒŸ Demo z deduplikacjÄ…
â”œâ”€â”€ test_deduplicate.py # ğŸ” Testy deduplikacji
â””â”€â”€ test_*.py          # Testy i demonstracje
```

## âš™ï¸ **KONFIGURACJA**

### Selenium
```python
# config.py
SELENIUM_ENABLED = True
SELENIUM_HEADLESS = True  
SELENIUM_TIMEOUT = 20
SELENIUM_WAIT_TIME = 2
```

### Deduplikacja
```python
# Dostosuj prÃ³g podobieÅ„stwa
deduplicated = deduplicate_listings(
    all_listings, 
    similarity_threshold=75.0,    # 0-100%
    keep_best_source=True         # Priorytet najlepszych portali
)
```

### Supabase
```sql
CREATE TABLE ogloszenia (
    id SERIAL PRIMARY KEY,
    title TEXT,
    price NUMERIC,
    price_currency TEXT,
    price_original TEXT,
    location TEXT,
    url TEXT UNIQUE,
    area TEXT,
    rooms TEXT,
    description TEXT,
    source TEXT,
    scraped_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW()
);
```

## ğŸ“‹ **DOSTÄ˜PNE KOMENDY**

```bash
# Demo i testy gÅ‚Ã³wne
python complete_demo.py             # â­ PeÅ‚na demonstracja + deduplikacja
python test_deduplicate.py          # ğŸ” Test deduplikacji
python test_selenium_scrapers.py    # Test Selenium
python working_demo.py              # Test bez Selenium

# Testy pomocnicze  
python test_scraper_no_db.py        # Test bez bazy
python test_supabase.py             # Test bazy danych

# GÅ‚Ã³wne dziaÅ‚anie
python main.py                      # â­ PeÅ‚ny scraper + Supabase + deduplikacja

# Parser adresÃ³w i geocoding
python address_parser.py --process  # ğŸ  Parsowanie adresÃ³w
python geocoding_updater.py --test  # ğŸŒ Test geocodingu
python geocoding_updater.py --update # ğŸŒ UzupeÅ‚nianie wspÃ³Å‚rzÄ™dnych
python check_geocoding.py           # ğŸ“Š Sprawdzenie geocodingu

# Debug
python debug_selenium.py            # Debug portali z Selenium
python test_geocoding_system.py     # ğŸ§ª Test systemu geocodingu
```

## ğŸ›¡ï¸ **ZABEZPIECZENIA I OPTYMALIZACJE**

- **Random User-Agents** (fake-useragent)
- **Headless Selenium** z anti-detection
- **Losowe opÃ³Åºnienia** miÄ™dzy requestami
- **Timeout handling** i retry logic
- **Error handling** z fallback
- **ğŸ” Deduplikacja** - oszczÄ™dnoÅ›Ä‡ ~35% miejsca w bazie
- **Priorytet ÅºrÃ³deÅ‚** - zachowuje najlepsze dane

## ğŸ“ˆ **WYDAJNOÅšÄ†**

- **Selenium portale**: ~3-5 sekund/strona
- **Requests portale**: ~1-2 sekundy/strona  
- **Deduplikacja**: ~0.1 sekunda/100 ogÅ‚oszeÅ„
- **ÅÄ…cznie**: 200+ ogÅ‚oszeÅ„ â†’ 128 unikatowych w ~3-4 minuty
- **OszczÄ™dnoÅ›Ä‡**: 35% mniej danych w bazie
- **Concurrent scraping**: MoÅ¼liwe rozszerzenie

## ğŸ”„ **AUTOMATYZACJA**

### Windows Task Scheduler
```batch
# Uruchamiaj co godzinÄ™ z deduplikacjÄ…
schtasks /create /tn "Scraper" /tr "python C:\path\to\main.py" /sc hourly
```

### Linux/Mac Cron
```bash
# Uruchamiaj co godzinÄ™ z deduplikacjÄ…
0 * * * * cd /path/to/scraper && python main.py
```

## ğŸ› **ROZWIÄ„ZYWANIE PROBLEMÃ“W**

### Deduplikacja
```bash
# Za agresywna - zwiÄ™ksz prÃ³g
similarity_threshold=85.0  # zamiast 75.0

# Za sÅ‚aba - zmniejsz prÃ³g  
similarity_threshold=65.0  # zamiast 75.0

# WyÅ‚Ä…cz priorytet ÅºrÃ³deÅ‚
keep_best_source=False
```

### Selenium nie dziaÅ‚a
```bash
# SprawdÅº instalacjÄ™
python -c "from selenium import webdriver; print('OK')"

# Zainstaluj ChromeDriver (Linux/Mac)
sudo apt install chromium-chromedriver
```

### Brak ogÅ‚oszeÅ„
- Portale czÄ™sto zmieniajÄ… strukturÄ™ HTML
- UÅ¼yj `debug_selenium.py` do analizy
- Zaktualizuj selektory CSS w scraperach

### Blokowanie
- ZwiÄ™ksz opÃ³Åºnienia w `config.py`
- Selenium ma lepszÄ… ochronÄ™ niÅ¼ Requests
- UÅ¼yj proxy (opcjonalnie)

## ğŸ“„ **LICENCJA**

MIT License - uÅ¼ywaj zgodnie z regulaminami scraperowanych portali.

## ğŸ¤ **ROZWÃ“J**

1. **Fork** repozytorium
2. **Dodaj nowy scraper** w `scrapers/`  
3. **Przetestuj** z `debug_selenium.py`
4. **Test deduplikacji** z `test_deduplicate.py`
5. **UtwÃ³rz PR** z opisem zmian

---

## ğŸŒ **GEOCODING I PARSER ADRESÃ“W**

### **Dodatkowe funkcjonalnoÅ›ci:**
âœ… **Parser adresÃ³w** - rozdziela lokalizacje na komponenty (miasto, dzielnica, ulica)  
âœ… **Geocoding** - automatyczne wspÃ³Å‚rzÄ™dne geograficzne (latitude, longitude)  
âœ… **API Nominatim** - darmowe geocoding bez limitÃ³w  
âœ… **Walidacja** - sprawdzanie czy wspÃ³Å‚rzÄ™dne sÄ… w Polsce  

### **Szybki start geocoding:**
```bash
# 1. Dodaj kolumny do tabeli addresses (SQL w Supabase)
# 2. Test geocodingu
python geocoding_updater.py --test

# 3. UzupeÅ‚nij wspÃ³Å‚rzÄ™dne
python geocoding_updater.py --update --max-addresses 50

# 4. SprawdÅº wyniki
python check_geocoding.py
```

### **Dokumentacja:**
- `README_GEOCODING.md` - **PeÅ‚na dokumentacja geocodingu** ğŸŒ
- `README_ADDRESS_PARSER.md` - **Dokumentacja parsera adresÃ³w** ğŸ 

---

## ğŸ‰ **SUKCES!**

System scrapuje **200+ ogÅ‚oszeÅ„** z **6 najwiÄ™kszych polskich portali nieruchomoÅ›ci**, **automatycznie usuwa ~35% duplikatÃ³w**, **parsuje adresy** i **dodaje wspÃ³Å‚rzÄ™dne geograficzne**! 

**Testuj**: `python complete_demo.py`  
**Deduplikacja**: `python test_deduplicate.py`  
**Geocoding**: `python test_geocoding_system.py`  
**Dokumentacja**: `INSTRUKCJE_URUCHOMIENIA.md`